{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(train_data, test_data, skiprows = 1):\n",
    "    '''\n",
    "    Function loads training and test data stored in input files in the same folder as load_data\n",
    "    and returns x_train, y_train, and x_test in numpy ndarrays.\n",
    "\n",
    "    Inputs:\n",
    "        train_data: training_data filename\n",
    "        test_data: test_data filename\n",
    "\n",
    "    Outputs:\n",
    "        x_train: x values for training set as numpy ndarray\n",
    "        y_train: labels for x values in training set as numpy ndarray\n",
    "        x_test: x values for testing set as numpy ndarray\n",
    "    '''\n",
    "\n",
    "    train_data = np.loadtxt(train_data, skiprows = skiprows, delimiter = ' ')\n",
    "\n",
    "    x_train = train_data[:, 1:]\n",
    "    y_train = train_data[0:,0]\n",
    "\n",
    "    x_test = np.loadtxt(test_data, skiprows = skiprows, delimiter = ' ')\n",
    "\n",
    "    return x_train, y_train, x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pam39\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "C:\\Users\\pam39\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "C:\\Users\\pam39\\Anaconda3\\lib\\site-packages\\sklearn\\grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#from process_input import load_data\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.layers import Flatten, BatchNormalization\n",
    "from keras import regularizers\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from keras.optimizers import SGD\n",
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 1000, 1)\n",
      "(10000, 1000, 1)\n",
      "(20000, 2)\n"
     ]
    }
   ],
   "source": [
    "train_file = \"data/training_data.txt\"\n",
    "test_file = \"data/test_data.txt\"\n",
    "x_train, y_train, x_test = load_data(train_file, test_file)\n",
    "\n",
    "# one-hot encode the labels\n",
    "y_train = keras.utils.np_utils.to_categorical(y_train)\n",
    "\n",
    "# normalize input data\n",
    "x_train = np.divide(x_train, x_train.max())\n",
    "x_test = np.divide(x_test, x_test.max())\n",
    "\n",
    "# we must reshape the X data (add a channel dimension)\n",
    "x_train = x_train.reshape(tuple(list(x_train.shape) + [1]))\n",
    "x_test = x_test.reshape(tuple(list(x_test.shape) + [1]))\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(optim = 'rmsprop', density = 100, rate = 0.15):\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=(1000,1))) \n",
    "    model.add(Dense(density))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(rate))\n",
    "\n",
    "    model.add(Dense(int(density / 10)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(rate))\n",
    "\n",
    "    model.add(Dense(int(density / 10)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(2))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy',optimizer=optim, metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 38.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.836400 using {'density': 300, 'epochs': 20, 'optim': 'nadam', 'rate': 0.3}\n",
      "0.836400 (0.004689) with: {'density': 300, 'epochs': 20, 'optim': 'nadam', 'rate': 0.3}\n"
     ]
    }
   ],
   "source": [
    "seed = 7\n",
    "model = KerasClassifier(build_fn=create_model, nb_epoch = 10, batch_size = 64, verbose = 0)\n",
    "rate = [0.3]\n",
    "optim = ['nadam']\n",
    "density = [300]\n",
    "\n",
    "param_grid = dict(optim = optim, rate = rate, density = density, epochs = [20])\n",
    "grid = GridSearchCV(estimator = model, param_grid = param_grid, verbose = 1, cv = 5)\n",
    "grid_result = grid.fit(x_train, y_train)\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "for params, mean_score, scores in grid_result.grid_scores_:\n",
    "    print(\"%f (%f) with: %r\" % (scores.mean(), scores.std(), params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20000"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.argmax(model.predict(x_test), axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
